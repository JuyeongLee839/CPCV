{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from CV import CPCV as CPCV\n",
    "\n",
    "from CV.util import StandardScaler, generate_xy_seq\n",
    "\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order \n",
    "1. X, Y generation \n",
    "2. CPCV baseline \n",
    "   어차피 여기서 뒤에서 개수만큼 잘라주는 거면 데이터 포인트를 자르는 것과 다를바 없음\n",
    "3. Path return function\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/data_input_demo.csv\", index_col = [0])\n",
    "df = df.set_index(['date'])[['13ty_index', 'interty_index', 'lty_index', 'mbs_index',\\\n",
    "       '13cy_index', 'intercy_index', 'lcy_index', 'ty_index', 'cy_index','agg_index']]\n",
    "df.index = pd.to_datetime(df.index, format = '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>13ty_index</th>\n",
       "      <th>interty_index</th>\n",
       "      <th>lty_index</th>\n",
       "      <th>mbs_index</th>\n",
       "      <th>13cy_index</th>\n",
       "      <th>intercy_index</th>\n",
       "      <th>lcy_index</th>\n",
       "      <th>ty_index</th>\n",
       "      <th>cy_index</th>\n",
       "      <th>agg_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-05-19</th>\n",
       "      <td>133.46</td>\n",
       "      <td>784.22</td>\n",
       "      <td>840.64</td>\n",
       "      <td>751.37</td>\n",
       "      <td>668.10</td>\n",
       "      <td>893.58</td>\n",
       "      <td>912.47</td>\n",
       "      <td>824.23</td>\n",
       "      <td>861.00</td>\n",
       "      <td>715.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-20</th>\n",
       "      <td>133.58</td>\n",
       "      <td>785.01</td>\n",
       "      <td>840.34</td>\n",
       "      <td>751.82</td>\n",
       "      <td>668.74</td>\n",
       "      <td>894.56</td>\n",
       "      <td>912.29</td>\n",
       "      <td>824.78</td>\n",
       "      <td>861.51</td>\n",
       "      <td>716.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-21</th>\n",
       "      <td>133.59</td>\n",
       "      <td>784.63</td>\n",
       "      <td>836.47</td>\n",
       "      <td>751.97</td>\n",
       "      <td>668.77</td>\n",
       "      <td>893.58</td>\n",
       "      <td>908.76</td>\n",
       "      <td>823.54</td>\n",
       "      <td>859.71</td>\n",
       "      <td>715.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-22</th>\n",
       "      <td>133.58</td>\n",
       "      <td>784.33</td>\n",
       "      <td>834.66</td>\n",
       "      <td>751.97</td>\n",
       "      <td>668.71</td>\n",
       "      <td>892.96</td>\n",
       "      <td>906.86</td>\n",
       "      <td>822.86</td>\n",
       "      <td>858.69</td>\n",
       "      <td>714.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-23</th>\n",
       "      <td>133.58</td>\n",
       "      <td>784.70</td>\n",
       "      <td>835.59</td>\n",
       "      <td>752.27</td>\n",
       "      <td>668.71</td>\n",
       "      <td>893.58</td>\n",
       "      <td>907.77</td>\n",
       "      <td>823.37</td>\n",
       "      <td>859.37</td>\n",
       "      <td>715.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            13ty_index  interty_index  lty_index  mbs_index  13cy_index  \\\n",
       "date                                                                      \n",
       "1997-05-19      133.46         784.22     840.64     751.37      668.10   \n",
       "1997-05-20      133.58         785.01     840.34     751.82      668.74   \n",
       "1997-05-21      133.59         784.63     836.47     751.97      668.77   \n",
       "1997-05-22      133.58         784.33     834.66     751.97      668.71   \n",
       "1997-05-23      133.58         784.70     835.59     752.27      668.71   \n",
       "\n",
       "            intercy_index  lcy_index  ty_index  cy_index  agg_index  \n",
       "date                                                                 \n",
       "1997-05-19         893.58     912.47    824.23    861.00     715.66  \n",
       "1997-05-20         894.56     912.29    824.78    861.51     716.09  \n",
       "1997-05-21         893.58     908.76    823.54    859.71     715.31  \n",
       "1997-05-22         892.96     906.86    822.86    858.69     714.88  \n",
       "1997-05-23         893.58     907.77    823.37    859.37     715.31  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X, Y generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_seq = 66\n",
    "future_seq = 22\n",
    "num_assets = df.shape[1]\n",
    "X, Y, X_date, Y_date = generate_xy_seq(df, x_seq = past_seq, y_seq = future_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6298, 66, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6298, 22, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6298, 66, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1997-05-19T00:00:00.000000000', '1997-05-20T00:00:00.000000000',\n",
       "        '1997-05-21T00:00:00.000000000', ...,\n",
       "        '1997-08-14T00:00:00.000000000', '1997-08-15T00:00:00.000000000',\n",
       "        '1997-08-18T00:00:00.000000000'],\n",
       "       ['1997-05-20T00:00:00.000000000', '1997-05-21T00:00:00.000000000',\n",
       "        '1997-05-22T00:00:00.000000000', ...,\n",
       "        '1997-08-15T00:00:00.000000000', '1997-08-18T00:00:00.000000000',\n",
       "        '1997-08-19T00:00:00.000000000'],\n",
       "       ['1997-05-21T00:00:00.000000000', '1997-05-22T00:00:00.000000000',\n",
       "        '1997-05-23T00:00:00.000000000', ...,\n",
       "        '1997-08-18T00:00:00.000000000', '1997-08-19T00:00:00.000000000',\n",
       "        '1997-08-20T00:00:00.000000000'],\n",
       "       ...,\n",
       "       ['2021-07-05T00:00:00.000000000', '2021-07-06T00:00:00.000000000',\n",
       "        '2021-07-07T00:00:00.000000000', ...,\n",
       "        '2021-09-30T00:00:00.000000000', '2021-10-01T00:00:00.000000000',\n",
       "        '2021-10-04T00:00:00.000000000'],\n",
       "       ['2021-07-06T00:00:00.000000000', '2021-07-07T00:00:00.000000000',\n",
       "        '2021-07-08T00:00:00.000000000', ...,\n",
       "        '2021-10-01T00:00:00.000000000', '2021-10-04T00:00:00.000000000',\n",
       "        '2021-10-05T00:00:00.000000000'],\n",
       "       ['2021-07-07T00:00:00.000000000', '2021-07-08T00:00:00.000000000',\n",
       "        '2021-07-09T00:00:00.000000000', ...,\n",
       "        '2021-10-04T00:00:00.000000000', '2021-10-05T00:00:00.000000000',\n",
       "        '2021-10-06T00:00:00.000000000']], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1997-08-19T00:00:00.000000000', '1997-08-20T00:00:00.000000000',\n",
       "        '1997-08-21T00:00:00.000000000', ...,\n",
       "        '1997-09-15T00:00:00.000000000', '1997-09-16T00:00:00.000000000',\n",
       "        '1997-09-17T00:00:00.000000000'],\n",
       "       ['1997-08-20T00:00:00.000000000', '1997-08-21T00:00:00.000000000',\n",
       "        '1997-08-22T00:00:00.000000000', ...,\n",
       "        '1997-09-16T00:00:00.000000000', '1997-09-17T00:00:00.000000000',\n",
       "        '1997-09-18T00:00:00.000000000'],\n",
       "       ['1997-08-21T00:00:00.000000000', '1997-08-22T00:00:00.000000000',\n",
       "        '1997-08-25T00:00:00.000000000', ...,\n",
       "        '1997-09-17T00:00:00.000000000', '1997-09-18T00:00:00.000000000',\n",
       "        '1997-09-19T00:00:00.000000000'],\n",
       "       ...,\n",
       "       ['2021-10-05T00:00:00.000000000', '2021-10-06T00:00:00.000000000',\n",
       "        '2021-10-07T00:00:00.000000000', ...,\n",
       "        '2021-11-01T00:00:00.000000000', '2021-11-02T00:00:00.000000000',\n",
       "        '2021-11-03T00:00:00.000000000'],\n",
       "       ['2021-10-06T00:00:00.000000000', '2021-10-07T00:00:00.000000000',\n",
       "        '2021-10-08T00:00:00.000000000', ...,\n",
       "        '2021-11-02T00:00:00.000000000', '2021-11-03T00:00:00.000000000',\n",
       "        '2021-11-04T00:00:00.000000000'],\n",
       "       ['2021-10-07T00:00:00.000000000', '2021-10-08T00:00:00.000000000',\n",
       "        '2021-10-11T00:00:00.000000000', ...,\n",
       "        '2021-11-03T00:00:00.000000000', '2021-11-04T00:00:00.000000000',\n",
       "        '2021-11-05T00:00:00.000000000']], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info_sets = pd.Series(index=df[:-(past_seq+future_seq-1)].index, data=df[(past_seq+future_seq-1):].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "1997-05-19   1997-09-17\n",
       "1997-05-20   1997-09-18\n",
       "1997-05-21   1997-09-19\n",
       "1997-05-22   1997-09-22\n",
       "1997-05-23   1997-09-23\n",
       "                ...    \n",
       "2021-07-01   2021-11-01\n",
       "2021-07-02   2021-11-02\n",
       "2021-07-05   2021-11-03\n",
       "2021-07-06   2021-11-04\n",
       "2021-07-07   2021-11-05\n",
       "Name: date, Length: 6298, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_info_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPCV with Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from CV.dataformatter import DataLoaderSet\n",
    "import torch \n",
    "from torch import nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6298, 66, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6298, 22, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, num_assets, past_seq, future_seq, num_layers, device):\n",
    "        '''\n",
    "        '''\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.device = device\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm_in_dim = num_assets\n",
    "        self.lstm_out_dim = num_assets \n",
    "        \n",
    "        self.fc_in_dim = past_seq\n",
    "        self.fc_out_dim = future_seq\n",
    "\n",
    "## LSTM 정의 \n",
    "        self.lstm = nn.LSTM(self.lstm_in_dim, self.lstm_out_dim, num_layers = self.num_layers, batch_first = True)\n",
    "        self.fc = nn.Conv2d(self.fc_in_dim, self.fc_out_dim, kernel_size= (1,1))        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: [batch size, past sequence]\n",
    "        '''\n",
    "        batch_size = x.size(0)\n",
    "## 초기 hidden state, cell state 정의해주기 : 0으로 준다\n",
    "        hidden_init = torch.zeros(self.num_layers, batch_size, self.lstm_out_dim).to(self.device)\n",
    "        cell_init = torch.zeros(self.num_layers, batch_size, self.lstm_out_dim).to(self.device)\n",
    "        \n",
    "        output, hidden = self.lstm(x, (hidden_init, cell_init))\n",
    "        prediction = output.unsqueeze(-1)\n",
    "        \n",
    "####### 예측길이 바꿔주고 싶을 때 실행        \n",
    "        prediction = self.fc(prediction)\n",
    "        prediction = prediction.squeeze()\n",
    "        \n",
    "        return prediction         \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use gpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print (\"Use gpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print (\"Use cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Model Loading **\n"
     ]
    }
   ],
   "source": [
    "# Model related hyper-parameters \n",
    "num_assets = df.shape[-1]\n",
    "num_layers = 1 \n",
    "num_epochs = 100\n",
    "\n",
    "######### Model 을 정의하는 부분 ########\n",
    "print (\"** Model Loading **\")\n",
    "Model = LSTM_Model(num_assets, past_seq, future_seq, num_layers, device)\n",
    "\n",
    "Model.to(device)\n",
    "\n",
    "criterion = nn.L1Loss() # Loss function 을 정의: MAE\n",
    "optimizer = torch.optim.Adam(Model.parameters(), lr = 0.01) # optimizer 을 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training related hyper-parameters\n",
    "batch_num = 32\n",
    "epoch_num = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPCV Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_split_num = 6\n",
    "val_split_num = 2\n",
    "pct_embargo = 0.01\n",
    "purge_behind = True\n",
    "\n",
    "\n",
    "folds = [i for i in range(total_split_num)]\n",
    "val_comb = list(combinations(folds, val_split_num))\n",
    "train_split_num = total_split_num - val_split_num\n",
    "path_fold_num  = train_split_num + 1 # 한 path 에 존재하는 fold 의 개수 / train_split_num + 1  = 5\n",
    "path_num = int(len(val_comb) * val_split_num / total_split_num) # 전체 path 의 개수 = path_fold_num \n",
    "\n",
    "cv_gen = CPCV.CombinatorialPurgedKFold(n_splits=total_split_num,\n",
    "                         n_valid_splits = val_split_num, \n",
    "                         samples_info_sets=sample_info_sets, \n",
    "                         pct_embargo=pct_embargo,\n",
    "                         purge_behind= purge_behind)\n",
    "\n",
    "cv_split = cv_gen.split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_params = {'batch_size': 32,\n",
    "                 'shuffle':True,\n",
    "                 'device':'cuda:0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (0, 4),\n",
       " (0, 5),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (1, 5),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (2, 5),\n",
       " (3, 4),\n",
       " (3, 5),\n",
       " (4, 5)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Number: 0\n",
      "** Model Loading **\n",
      "DataLoader generation...\n",
      "Training...\n",
      "Validation...\n",
      "Split Number: 1\n",
      "** Model Loading **\n",
      "DataLoader generation...\n",
      "Training...\n",
      "Validation...\n",
      "Split Number: 2\n",
      "** Model Loading **\n",
      "DataLoader generation...\n",
      "Training...\n",
      "Validation...\n",
      "Split Number: 3\n",
      "** Model Loading **\n",
      "DataLoader generation...\n",
      "Training...\n",
      "Validation...\n",
      "Split Number: 4\n",
      "** Model Loading **\n",
      "DataLoader generation...\n",
      "Training...\n",
      "Validation...\n",
      "Split Number: 5\n",
      "** Model Loading **\n",
      "DataLoader generation...\n",
      "Training...\n",
      "Validation...\n",
      "Split Number: 6\n",
      "** Model Loading **\n",
      "DataLoader generation...\n",
      "Training...\n",
      "Validation...\n",
      "Split Number: 7\n",
      "** Model Loading **\n",
      "DataLoader generation...\n",
      "Training...\n",
      "Validation...\n",
      "Split Number: 8\n",
      "** Model Loading **\n",
      "DataLoader generation...\n",
      "Training...\n",
      "Validation...\n",
      "Split Number: 9\n",
      "** Model Loading **\n",
      "DataLoader generation...\n",
      "Training...\n",
      "Validation...\n",
      "Split Number: 10\n",
      "** Model Loading **\n",
      "DataLoader generation...\n",
      "Training...\n",
      "Validation...\n",
      "Split Number: 11\n",
      "** Model Loading **\n",
      "DataLoader generation...\n",
      "Training...\n",
      "Validation...\n",
      "Split Number: 12\n",
      "** Model Loading **\n",
      "DataLoader generation...\n",
      "Training...\n",
      "Validation...\n",
      "Split Number: 13\n",
      "** Model Loading **\n",
      "DataLoader generation...\n",
      "Training...\n",
      "Validation...\n",
      "Split Number: 14\n",
      "** Model Loading **\n",
      "DataLoader generation...\n",
      "Training...\n",
      "Validation...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_loss = [0 for _ in range(path_num)]\n",
    "\n",
    "for idx, (path_ind_ls, train_ind, valid_ind_set) in enumerate(cv_split): # 결국 순서대로 -> 순서 자체가 train model number\n",
    "    \n",
    "    print ('Split Number:', idx)\n",
    "    # MODEL INIT\n",
    "    ######### Model 을 정의하는 부분 ########\n",
    "    print (\"** Model Loading **\")\n",
    "    Model = LSTM_Model(num_assets, past_seq, future_seq, num_layers, device)\n",
    "\n",
    "    Model.to(device)\n",
    "\n",
    "    criterion = nn.L1Loss() # Loss function 을 정의합니다 : MAE\n",
    "    optimizer = torch.optim.Adam(Model.parameters(), lr = 0.01) # optimizer 을 설정해 줍니다. \n",
    "    \n",
    "    # DataLoader \n",
    "    print (\"DataLoader generation...\")\n",
    "    LoaderGenerator = DataLoaderSet(X, Y, X_date, Y_date, path_ind_ls, train_ind, valid_ind_set, loader_params)\n",
    "    loader_set = LoaderGenerator.dataloader\n",
    "    \n",
    "    # scaler2 for prediction during training\n",
    "    mean2 = torch.from_numpy(LoaderGenerator.scaler.mean).to(device)\n",
    "    std2 = torch.from_numpy(LoaderGenerator.scaler.std).to(device)\n",
    "\n",
    "    scaler2 = StandardScaler(mean2, std2)\n",
    "    # TRAIN     \n",
    "    # Epoch \n",
    "    print (\"Training...\")\n",
    "    for epoch in range(epoch_num):\n",
    "        Model.train()\n",
    "        epoch_train_loss = []\n",
    "        \n",
    "        train_loader = loader_set['train_loader']\n",
    "        for train_x, train_y, dates in train_loader.get_iterator():\n",
    "            \n",
    "            train_pred = Model(train_x)\n",
    "            \n",
    "            train_pred = scaler2.inverse_transform(train_pred)\n",
    "            \n",
    "            loss_train = criterion(train_pred, train_y)\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "    # Validation \n",
    "    print (\"Validation...\")\n",
    "    Model.eval()\n",
    "    valid_loader_set = loader_set['valid_loader']\n",
    "    \n",
    "    for path_num in list(valid_loader_set.keys()):\n",
    "        # print (\"Path num: \", path_num)\n",
    "        n_valid_loader = valid_loader_set[path_num]\n",
    "        for valid_x, valid_y, dates in n_valid_loader.get_iterator():\n",
    "            val_pred = Model(valid_x)\n",
    "            val_pred = scaler2.inverse_transform(val_pred)\n",
    "            \n",
    "            val_loss = criterion(val_pred, valid_y)\n",
    "            \n",
    "            total_loss[path_num] += val_loss\n",
    "            \n",
    "for i in range(len(total_loss)):\n",
    "    total_loss[i] /= total_split_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "plt.title(\"Loss by Path\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Path Number\")\n",
    "plt.bar([i+1 for i in range(len(total_loss))] ,[np.array(x.detach().cpu()) for x in total_loss])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26b462196a458278e1b93f4dafd0c6a4f17b941fc39fbc23177d70dd3e3b7653"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('tft')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
