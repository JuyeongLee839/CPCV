{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import datetime \n",
    "\n",
    "from CV import cross_validation as CV\n",
    "from CV import combinatorial as CB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order \n",
    "1. X, Y generation \n",
    "2. Train(valid) / Test splitting\n",
    "3. CPCV\n",
    "   어차피 여기서 뒤에서 개수만큼 잘라주는 거면 데이터 포인트를 자르는 것과 다를바 없음\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/data_input_demo.csv\", index_col = [0])\n",
    "df = df.set_index(['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>13ty_index</th>\n",
       "      <th>interty_index</th>\n",
       "      <th>lty_index</th>\n",
       "      <th>mbs_index</th>\n",
       "      <th>13cy_index</th>\n",
       "      <th>intercy_index</th>\n",
       "      <th>lcy_index</th>\n",
       "      <th>ty_index</th>\n",
       "      <th>cy_index</th>\n",
       "      <th>agg_index</th>\n",
       "      <th>real_known</th>\n",
       "      <th>cat_obs1</th>\n",
       "      <th>cat_obs2</th>\n",
       "      <th>cat_knwon1</th>\n",
       "      <th>cat_knwon2</th>\n",
       "      <th>static</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-05-19</th>\n",
       "      <td>133.46</td>\n",
       "      <td>784.22</td>\n",
       "      <td>840.64</td>\n",
       "      <td>751.37</td>\n",
       "      <td>668.10</td>\n",
       "      <td>893.58</td>\n",
       "      <td>912.47</td>\n",
       "      <td>824.23</td>\n",
       "      <td>861.00</td>\n",
       "      <td>715.66</td>\n",
       "      <td>215.632652</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-20</th>\n",
       "      <td>133.58</td>\n",
       "      <td>785.01</td>\n",
       "      <td>840.34</td>\n",
       "      <td>751.82</td>\n",
       "      <td>668.74</td>\n",
       "      <td>894.56</td>\n",
       "      <td>912.29</td>\n",
       "      <td>824.78</td>\n",
       "      <td>861.51</td>\n",
       "      <td>716.09</td>\n",
       "      <td>980.112727</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-21</th>\n",
       "      <td>133.59</td>\n",
       "      <td>784.63</td>\n",
       "      <td>836.47</td>\n",
       "      <td>751.97</td>\n",
       "      <td>668.77</td>\n",
       "      <td>893.58</td>\n",
       "      <td>908.76</td>\n",
       "      <td>823.54</td>\n",
       "      <td>859.71</td>\n",
       "      <td>715.31</td>\n",
       "      <td>247.766286</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-22</th>\n",
       "      <td>133.58</td>\n",
       "      <td>784.33</td>\n",
       "      <td>834.66</td>\n",
       "      <td>751.97</td>\n",
       "      <td>668.71</td>\n",
       "      <td>892.96</td>\n",
       "      <td>906.86</td>\n",
       "      <td>822.86</td>\n",
       "      <td>858.69</td>\n",
       "      <td>714.88</td>\n",
       "      <td>306.038065</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-23</th>\n",
       "      <td>133.58</td>\n",
       "      <td>784.70</td>\n",
       "      <td>835.59</td>\n",
       "      <td>752.27</td>\n",
       "      <td>668.71</td>\n",
       "      <td>893.58</td>\n",
       "      <td>907.77</td>\n",
       "      <td>823.37</td>\n",
       "      <td>859.37</td>\n",
       "      <td>715.31</td>\n",
       "      <td>944.644883</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            13ty_index  interty_index  lty_index  mbs_index  13cy_index  \\\n",
       "date                                                                      \n",
       "1997-05-19      133.46         784.22     840.64     751.37      668.10   \n",
       "1997-05-20      133.58         785.01     840.34     751.82      668.74   \n",
       "1997-05-21      133.59         784.63     836.47     751.97      668.77   \n",
       "1997-05-22      133.58         784.33     834.66     751.97      668.71   \n",
       "1997-05-23      133.58         784.70     835.59     752.27      668.71   \n",
       "\n",
       "            intercy_index  lcy_index  ty_index  cy_index  agg_index  \\\n",
       "date                                                                  \n",
       "1997-05-19         893.58     912.47    824.23    861.00     715.66   \n",
       "1997-05-20         894.56     912.29    824.78    861.51     716.09   \n",
       "1997-05-21         893.58     908.76    823.54    859.71     715.31   \n",
       "1997-05-22         892.96     906.86    822.86    858.69     714.88   \n",
       "1997-05-23         893.58     907.77    823.37    859.37     715.31   \n",
       "\n",
       "            real_known  cat_obs1  cat_obs2  cat_knwon1  cat_knwon2  static  \n",
       "date                                                                        \n",
       "1997-05-19  215.632652         2         2           4           3     1.0  \n",
       "1997-05-20  980.112727         2         1           5           4     1.0  \n",
       "1997-05-21  247.766286         2         1           4           4     1.0  \n",
       "1997-05-22  306.038065         2         1           3           4     1.0  \n",
       "1997-05-23  944.644883         0         2           3           3     1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_xy_seq(df: pd.DataFrame, x_seq = 66, y_seq = 22):\n",
    "    \"\"\"\n",
    "    Generate samples from\n",
    "    :param df:\n",
    "    :param x_seq:\n",
    "    :param y_seq:\n",
    "    :param scaler:\n",
    "    :return:\n",
    "    # x: (epoch_size, input_length, num_nodes, input_dim)\n",
    "    # y: (epoch_size, output_length, num_nodes, output_dim)\n",
    "    \"\"\"\n",
    "    num_samples, num_nodes = df.shape\n",
    "    dates_arr = np.array(df.index)\n",
    "    data = np.expand_dims(df.values, axis = -1) # df -> array [N, F, 1]\n",
    "\n",
    "    x_offsets = np.arange(-x_seq+1, 1)  \n",
    "    y_offsets = np.arange(1, y_seq+1)\n",
    "\n",
    "    # feature_list = [data]\n",
    "\n",
    "    x, y = [], []\n",
    "    x_date, y_date = [],[]\n",
    "\n",
    "    min_t = abs(min(x_offsets))\n",
    "    max_t = abs(num_samples - abs(max(y_offsets)))\n",
    "\n",
    "    for t in range(min_t, max_t):\n",
    "        # value seperation\n",
    "        x.append(data[t+x_offsets, ...])\n",
    "        y.append(data[t+y_offsets, ...])\n",
    "        # date seperation\n",
    "        x_date.append(dates_arr[t+x_offsets])\n",
    "        y_date.append(dates_arr[t+y_offsets])\n",
    "        \n",
    "    x = np.stack(x, axis = 0)\n",
    "    y = np.stack(y, axis = 0)\n",
    "\n",
    "    x_date = np.stack(x_date, axis = 0)\n",
    "    y_date = np.stack(y_date, axis = 0)\n",
    "\n",
    "    return x, y, x_date, y_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, x_date, y_date = generate_xy_seq(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6298, 66, 16, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6298, 66)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_date.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Path Num by train/test index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination \n",
    "total_split_num = 10\n",
    "val_split_num = 2\n",
    "\n",
    "folds = [i for i in range(total_split_num)]\n",
    "val_comb = list(combinations(folds, val_split_num))\n",
    "fold_set = [(ix[0], ix[-1] + 1) for ix in np.array_split(np.arange(X.shape[0]), 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [2], [3], [4], [5], [6], [7], [8]]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path Generation \n",
    "train_split_num = total_split_num - val_split_num\n",
    "\n",
    "path_fold_num  = train_split_num + 1 # 한 path 에 존재하는 fold 의 개수 / train_split_num + 1  = 5\n",
    "path_num = int(len(val_comb) * val_split_num / total_split_num) # 전체 path 의 개수 = path_fold_num \n",
    "\n",
    "model_num = len(val_comb) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_split_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Path 별 Train model index\n",
    "\n",
    "1. Path 별 Train model index 정하기 \n",
    "    1) path 별 block 개수를 정한다. (전체 split 개수 - test split 개수)\n",
    "    2) 전체 path 개수를 정한다. \n",
    "    3) path 별 model 의 index 를 결정해준다. \n",
    "        - i-th path 의 first value : i \n",
    "        - 각 path 의 j-th value : (j-1)th value + train_split_num - (j-1)\n",
    "        - i-th path 의 (i+1)-th value 부터는 path_i[i] + 1\n",
    "\n",
    "2. Path 별 하나의 Train 별 test set index \n",
    "\n",
    "    하나의 train 에 대해서 test set 두개 존재 \n",
    "    두개중 어떤 것이 해당 path 에 해당되는 것인지 확인 \n",
    "    \n",
    "3. \n",
    "'''\n",
    "total_path_train = {}\n",
    "\n",
    "for path_ind in range(path_num): # \n",
    "    train_model_ind = {}\n",
    "    path_ls = []\n",
    "    if path_ind == 0 :   \n",
    "        firstfold = [i for i in range(path_fold_num)]\n",
    "        firstfold = [x  for x in firstfold]\n",
    "        total_path_train[path_ind] = (firstfold)\n",
    "        \n",
    "    else:\n",
    "        path_ls = [0 for _ in range(path_fold_num)] # [0, 0, 0, 0, 0]\n",
    "        path_ls[0] = path_ind\n",
    "        \n",
    "        for minus in range(train_split_num):\n",
    "            ind = minus + 1\n",
    "            if ind <= path_ind: # ind : 채워 넣고자 하는 위치\n",
    "                path_ls[ind] = path_ls[ind-1] + train_split_num - minus\n",
    "            else: # ind > path_ind \n",
    "                path_ls[ind] = path_ls[ind-1] + 1\n",
    "        path_ls = [x for x in path_ls]\n",
    "        total_path_train[path_ind] = path_ls\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 1: [1, 9, 10, 11, 12, 13, 14, 15, 16],\n",
       " 2: [2, 10, 17, 18, 19, 20, 21, 22, 23],\n",
       " 3: [3, 11, 18, 24, 25, 26, 27, 28, 29],\n",
       " 4: [4, 12, 19, 25, 30, 31, 32, 33, 34],\n",
       " 5: [5, 13, 20, 26, 31, 35, 36, 37, 38],\n",
       " 6: [6, 14, 21, 27, 32, 36, 39, 40, 41],\n",
       " 7: [7, 15, 22, 28, 33, 37, 40, 42, 43],\n",
       " 8: [8, 16, 23, 29, 34, 38, 41, 43, 44]}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_path_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path 별 TEST set \n",
    "total_path_test = {}\n",
    "\n",
    "for path_ind in range(path_num):\n",
    "    a = [0 for i in range(total_split_num-1)] # 각 path 에 대해서 test set 의 index 저장\n",
    "\n",
    "    for split_ind in range(total_split_num-1):\n",
    "        \n",
    "        if split_ind < path_ind:\n",
    "            a[split_ind] = 0        \n",
    "        elif path_ind == split_ind:\n",
    "            a[split_ind] = [0,1]\n",
    "            \n",
    "        else: # split_ind > path_ind\n",
    "            a[split_ind] = 1\n",
    "            \n",
    "    total_path_test[path_ind] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 1: [1, 9, 10, 11, 12, 13, 14, 15, 16],\n",
       " 2: [2, 10, 17, 18, 19, 20, 21, 22, 23],\n",
       " 3: [3, 11, 18, 24, 25, 26, 27, 28, 29],\n",
       " 4: [4, 12, 19, 25, 30, 31, 32, 33, 34],\n",
       " 5: [5, 13, 20, 26, 31, 35, 36, 37, 38],\n",
       " 6: [6, 14, 21, 27, 32, 36, 39, 40, 41],\n",
       " 7: [7, 15, 22, 28, 33, 37, 40, 42, 43],\n",
       " 8: [8, 16, 23, 29, 34, 38, 41, 43, 44]}"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_path_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[0, 1], 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 1: [0, [0, 1], 1, 1, 1, 1, 1, 1, 1],\n",
       " 2: [0, 0, [0, 1], 1, 1, 1, 1, 1, 1],\n",
       " 3: [0, 0, 0, [0, 1], 1, 1, 1, 1, 1],\n",
       " 4: [0, 0, 0, 0, [0, 1], 1, 1, 1, 1],\n",
       " 5: [0, 0, 0, 0, 0, [0, 1], 1, 1, 1],\n",
       " 6: [0, 0, 0, 0, 0, 0, [0, 1], 1, 1],\n",
       " 7: [0, 0, 0, 0, 0, 0, 0, [0, 1], 1],\n",
       " 8: [0, 0, 0, 0, 0, 0, 0, 0, [0, 1]]}"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_path_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [1, 9, 10, 11, 12, 13, 14, 15, 16],\n",
       " [2, 10, 17, 18, 19, 20, 21, 22, 23],\n",
       " [3, 11, 18, 24, 25, 26, 27, 28, 29],\n",
       " [4, 12, 19, 25, 30, 31, 32, 33, 34],\n",
       " [5, 13, 20, 26, 31, 35, 36, 37, 38],\n",
       " [6, 14, 21, 27, 32, 36, 39, 40, 41],\n",
       " [7, 15, 22, 28, 33, 37, 40, 42, 43],\n",
       " [8, 16, 23, 29, 34, 38, 41, 43, 44]]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(total_path_train.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [0, (0, 1), 1, 1, 1, 1, 1, 1, 1],\n",
       " [0, 0, (0, 1), 1, 1, 1, 1, 1, 1],\n",
       " [0, 0, 0, (0, 1), 1, 1, 1, 1, 1],\n",
       " [0, 0, 0, 0, (0, 1), 1, 1, 1, 1],\n",
       " [0, 0, 0, 0, 0, (0, 1), 1, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, (0, 1), 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, (0, 1), 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, (0, 1)]]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(total_path_test.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test index 별 path 번호 \n",
    "tr_ts_ind_path = {} \n",
    "\n",
    "for path_ind in range(path_num):\n",
    "    for split_ind in range(9):\n",
    "        tr_ind = list(total_path_train.values())[path_ind][split_ind]\n",
    "        ts_ind = list(total_path_test.values())[path_ind][split_ind]\n",
    "        if type(ts_ind) == list:\n",
    "            for ts in ts_ind:\n",
    "                tr_ts_ind_path[tr_ind, ts] = path_ind\n",
    "        else:\n",
    "            tr_ts_ind_path[tr_ind, ts_ind] = path_ind\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 0,\n",
       " (0, 1): 0,\n",
       " (1, 1): 0,\n",
       " (2, 1): 0,\n",
       " (3, 1): 0,\n",
       " (4, 1): 0,\n",
       " (5, 1): 0,\n",
       " (6, 1): 0,\n",
       " (7, 1): 0,\n",
       " (8, 1): 0,\n",
       " (1, 0): 1,\n",
       " (9, 0): 1,\n",
       " (9, 1): 1,\n",
       " (10, 1): 1,\n",
       " (11, 1): 1,\n",
       " (12, 1): 1,\n",
       " (13, 1): 1,\n",
       " (14, 1): 1,\n",
       " (15, 1): 1,\n",
       " (16, 1): 1,\n",
       " (2, 0): 2,\n",
       " (10, 0): 2,\n",
       " (17, 0): 2,\n",
       " (17, 1): 2,\n",
       " (18, 1): 2,\n",
       " (19, 1): 2,\n",
       " (20, 1): 2,\n",
       " (21, 1): 2,\n",
       " (22, 1): 2,\n",
       " (23, 1): 2,\n",
       " (3, 0): 3,\n",
       " (11, 0): 3,\n",
       " (18, 0): 3,\n",
       " (24, 0): 3,\n",
       " (24, 1): 3,\n",
       " (25, 1): 3,\n",
       " (26, 1): 3,\n",
       " (27, 1): 3,\n",
       " (28, 1): 3,\n",
       " (29, 1): 3,\n",
       " (4, 0): 4,\n",
       " (12, 0): 4,\n",
       " (19, 0): 4,\n",
       " (25, 0): 4,\n",
       " (30, 0): 4,\n",
       " (30, 1): 4,\n",
       " (31, 1): 4,\n",
       " (32, 1): 4,\n",
       " (33, 1): 4,\n",
       " (34, 1): 4,\n",
       " (5, 0): 5,\n",
       " (13, 0): 5,\n",
       " (20, 0): 5,\n",
       " (26, 0): 5,\n",
       " (31, 0): 5,\n",
       " (35, 0): 5,\n",
       " (35, 1): 5,\n",
       " (36, 1): 5,\n",
       " (37, 1): 5,\n",
       " (38, 1): 5,\n",
       " (6, 0): 6,\n",
       " (14, 0): 6,\n",
       " (21, 0): 6,\n",
       " (27, 0): 6,\n",
       " (32, 0): 6,\n",
       " (36, 0): 6,\n",
       " (39, 0): 6,\n",
       " (39, 1): 6,\n",
       " (40, 1): 6,\n",
       " (41, 1): 6,\n",
       " (7, 0): 7,\n",
       " (15, 0): 7,\n",
       " (22, 0): 7,\n",
       " (28, 0): 7,\n",
       " (33, 0): 7,\n",
       " (37, 0): 7,\n",
       " (40, 0): 7,\n",
       " (42, 0): 7,\n",
       " (42, 1): 7,\n",
       " (43, 1): 7,\n",
       " (8, 0): 8,\n",
       " (16, 0): 8,\n",
       " (23, 0): 8,\n",
       " (29, 0): 8,\n",
       " (34, 0): 8,\n",
       " (38, 0): 8,\n",
       " (41, 0): 8,\n",
       " (43, 0): 8,\n",
       " (44, 0): 8,\n",
       " (44, 1): 8}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_ts_ind_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set 3 개 일 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from itertools import combinations\n",
    "\n",
    "# combination \n",
    "total_split_num = 6\n",
    "val_split_num = 3\n",
    "\n",
    "folds = [i for i in range(total_split_num)]\n",
    "val_comb = list(combinations(folds, val_split_num))\n",
    "fold_set = [(ix[0], ix[-1] + 1) for ix in np.array_split(np.arange(X.shape[0]), 6)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 2),\n",
       " (0, 1, 3),\n",
       " (0, 1, 4),\n",
       " (0, 1, 5),\n",
       " (0, 2, 3),\n",
       " (0, 2, 4),\n",
       " (0, 2, 5),\n",
       " (0, 3, 4),\n",
       " (0, 3, 5),\n",
       " (0, 4, 5),\n",
       " (1, 2, 3),\n",
       " (1, 2, 4),\n",
       " (1, 2, 5),\n",
       " (1, 3, 4),\n",
       " (1, 3, 5),\n",
       " (1, 4, 5),\n",
       " (2, 3, 4),\n",
       " (2, 3, 5),\n",
       " (2, 4, 5),\n",
       " (3, 4, 5)]"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path Generation \n",
    "train_split_num = total_split_num - val_split_num\n",
    "\n",
    "path_fold_num  = train_split_num + 1 # 한 path 에 존재하는 fold 의 개수 / train_split_num + 1  = 5\n",
    "path_num = int(len(val_comb) * val_split_num / total_split_num) # 전체 path 의 개수 = path_fold_num "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_fold_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# total_path_train \n",
    "    # Path 별 train number\n",
    "'''\n",
    "Path 별 Train model index\n",
    "\n",
    "1. Path 별 Train model index 정하기 \n",
    "    1) path 별 block 개수를 정한다. (전체 split 개수 - test split 개수)\n",
    "    2) 전체 path 개수를 정한다. \n",
    "    3) path 별 model 의 index 를 결정해준다. \n",
    "        - i-th path 의 first value : i \n",
    "        - 각 path 의 j-th value : (j-1)th value + train_split_num - (j-1)\n",
    "        - i-th path 의 (i+1)-th value 부터는 path_i[i] + 1\n",
    "\n",
    "2. Path 별 하나의 Train 별 test set index \n",
    "\n",
    "    하나의 train 에 대해서 test set 두개 존재 \n",
    "    두개중 어떤 것이 해당 path 에 해당되는 것인지 확인 \n",
    "    \n",
    "3. \n",
    "'''\n",
    "total_path_train = {}\n",
    "\n",
    "for path_ind in range(path_num): # \n",
    "    train_model_ind = {}\n",
    "    path_ls = []\n",
    "    if path_ind == 0 :   \n",
    "        firstfold = [i for i in range(path_fold_num)]\n",
    "        firstfold = [x  for x in firstfold]\n",
    "        total_path_train[path_ind] = (firstfold)\n",
    "    \n",
    "    elif path_ind <= (path_fold_num-1):\n",
    "        path_ls = [0 for _ in range(path_fold_num)] # [0, 0, 0, 0, 0]\n",
    "        path_ls[0] = path_ind\n",
    "        for minus in range(train_split_num):\n",
    "            ind = minus + 1\n",
    "            if ind <= path_ind: # ind : 채워 넣고자 하는 위치\n",
    "                path_ls[ind] = path_ls[ind-1] + train_split_num - minus\n",
    "            else: # ind > path_ind \n",
    "                if ind > path_fold_num:\n",
    "                  path_ls[ind] = path_ls[ind-1] + 6  \n",
    "                # path_ls[ind] = path_ls[ind-1] + 1\n",
    "                path_ls[ind] = path_ls[ind-1] + 1\n",
    "    \n",
    "    elif path_ind >= path_fold_num:\n",
    "        path_ls = [0 for _ in range(path_fold_num)] # [0, 0, 0, 0, 0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "                    \n",
    "        path_ls = [x for x in path_ls]\n",
    "        total_path_train[path_ind] = path_ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_fold_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, 1, 2, 3],\n",
       " 1: [1, 4, 5, 6],\n",
       " 2: [2, 5, 7, 8],\n",
       " 3: [3, 6, 8, 9],\n",
       " 4: [4, 7, 9, 10],\n",
       " 5: [5, 8, 10, 11],\n",
       " 6: [6, 9, 11, 12],\n",
       " 7: [7, 10, 12, 13],\n",
       " 8: [8, 11, 13, 14],\n",
       " 9: [9, 12, 14, 15]}"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_path_train # 6C3 d일경우 0~3까지 작동 ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: [4, 10, 11, 12]}"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{4: [4, 10, 11, 12]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path 별 TEST set \n",
    "total_path_test = {}\n",
    "\n",
    "for path_ind in range(path_num):\n",
    "    a = [0 for i in range(total_split_num-1)] # 각 path 에 대해서 test set 의 index 저장\n",
    "    for split_ind in range(total_split_num-1):\n",
    "        if split_ind < path_ind:\n",
    "            a[split_ind] = 0        \n",
    "        elif path_ind == split_ind:\n",
    "            a[split_ind] = [0,1,2]\n",
    "        else: # split_ind > path_ind\n",
    "            a[split_ind] = 1\n",
    "    total_path_test[path_ind] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[0, 1, 2], 1, 1, 1, 1],\n",
       " 1: [0, [0, 1, 2], 1, 1, 1],\n",
       " 2: [0, 0, [0, 1, 2], 1, 1],\n",
       " 3: [0, 0, 0, [0, 1, 2], 1],\n",
       " 4: [0, 0, 0, 0, [0, 1, 2]],\n",
       " 5: [0, 0, 0, 0, 0],\n",
       " 6: [0, 0, 0, 0, 0],\n",
       " 7: [0, 0, 0, 0, 0],\n",
       " 8: [0, 0, 0, 0, 0],\n",
       " 9: [0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_path_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test index 별 path 번호 \n",
    "# search_path_num\n",
    "tr_ts_ind_path = {} \n",
    "for path_ind in range(path_num):\n",
    "    for split_ind in range(total_split_num - 1):\n",
    "        tr_ind = list(total_path_train.values())[path_ind][split_ind]\n",
    "        ts_ind = list(total_path_test.values())[path_ind][split_ind]\n",
    "        if type(ts_ind) == list:\n",
    "            for ts in ts_ind:\n",
    "                tr_ts_ind_path[tr_ind, ts] = path_ind\n",
    "        else:\n",
    "            tr_ts_ind_path[tr_ind, ts_ind] = path_ind\n",
    "        # tr_ts_ind_path = {(0,0): 0, (0,1): 0, (1,1): 0, ..., (43,1):8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathmap = TrainValidPathNum(total_split_num, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_path = pathmap.train_valid_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 0,\n",
       " (0, 1): 0,\n",
       " (1, 1): 0,\n",
       " (2, 1): 0,\n",
       " (3, 1): 0,\n",
       " (4, 1): 0,\n",
       " (5, 1): 0,\n",
       " (6, 1): 0,\n",
       " (7, 1): 0,\n",
       " (8, 1): 0,\n",
       " (1, 0): 1,\n",
       " (9, 0): 1,\n",
       " (9, 1): 1,\n",
       " (10, 1): 1,\n",
       " (11, 1): 1,\n",
       " (12, 1): 1,\n",
       " (13, 1): 1,\n",
       " (14, 1): 1,\n",
       " (15, 1): 1,\n",
       " (16, 1): 1,\n",
       " (2, 0): 2,\n",
       " (10, 0): 2,\n",
       " (17, 0): 2,\n",
       " (17, 1): 2,\n",
       " (18, 1): 2,\n",
       " (19, 1): 2,\n",
       " (20, 1): 2,\n",
       " (21, 1): 2,\n",
       " (22, 1): 2,\n",
       " (23, 1): 2,\n",
       " (3, 0): 3,\n",
       " (11, 0): 3,\n",
       " (18, 0): 3,\n",
       " (24, 0): 3,\n",
       " (24, 1): 3,\n",
       " (25, 1): 3,\n",
       " (26, 1): 3,\n",
       " (27, 1): 3,\n",
       " (28, 1): 3,\n",
       " (29, 1): 3,\n",
       " (4, 0): 4,\n",
       " (12, 0): 4,\n",
       " (19, 0): 4,\n",
       " (25, 0): 4,\n",
       " (30, 0): 4,\n",
       " (30, 1): 4,\n",
       " (31, 1): 4,\n",
       " (32, 1): 4,\n",
       " (33, 1): 4,\n",
       " (34, 1): 4,\n",
       " (5, 0): 5,\n",
       " (13, 0): 5,\n",
       " (20, 0): 5,\n",
       " (26, 0): 5,\n",
       " (31, 0): 5,\n",
       " (35, 0): 5,\n",
       " (35, 1): 5,\n",
       " (36, 1): 5,\n",
       " (37, 1): 5,\n",
       " (38, 1): 5,\n",
       " (6, 0): 6,\n",
       " (14, 0): 6,\n",
       " (21, 0): 6,\n",
       " (27, 0): 6,\n",
       " (32, 0): 6,\n",
       " (36, 0): 6,\n",
       " (39, 0): 6,\n",
       " (39, 1): 6,\n",
       " (40, 1): 6,\n",
       " (41, 1): 6,\n",
       " (7, 0): 7,\n",
       " (15, 0): 7,\n",
       " (22, 0): 7,\n",
       " (28, 0): 7,\n",
       " (33, 0): 7,\n",
       " (37, 0): 7,\n",
       " (40, 0): 7,\n",
       " (42, 0): 7,\n",
       " (42, 1): 7,\n",
       " (43, 1): 7,\n",
       " (8, 0): 8,\n",
       " (16, 0): 8,\n",
       " (23, 0): 8,\n",
       " (29, 0): 8,\n",
       " (34, 0): 8,\n",
       " (38, 0): 8,\n",
       " (41, 0): 8,\n",
       " (43, 0): 8,\n",
       " (44, 0): 8,\n",
       " (44, 1): 8}"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_valid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPCV Path \n",
    "    # block 별로 path counting 하기 \n",
    "\n",
    "n_splits = 6\n",
    "n_val = 2\n",
    "\n",
    "splits = [i for i in range(n_splits)]\n",
    "val_comb = list(combinations(splits, n_val))\n",
    "total_train_num = len(val_comb)\n",
    "\n",
    "train_path_count = [0 for _ in range(n_splits)]\n",
    "train_path_pair = {}\n",
    "for val_group in val_comb:\n",
    "    path_comb = []\n",
    "    for split_ind in val_group:\n",
    "        path_comb.append(train_path_count[split_ind])\n",
    "        train_path_count[split_ind]+=1\n",
    "    \n",
    "    train_path_pair[val_group] = tuple(path_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1): (0, 0),\n",
       " (0, 2): (1, 0),\n",
       " (0, 3): (2, 0),\n",
       " (0, 4): (3, 0),\n",
       " (0, 5): (4, 0),\n",
       " (1, 2): (1, 1),\n",
       " (1, 3): (2, 1),\n",
       " (1, 4): (3, 1),\n",
       " (1, 5): (4, 1),\n",
       " (2, 3): (2, 2),\n",
       " (2, 4): (3, 2),\n",
       " (2, 5): (4, 2),\n",
       " (3, 4): (3, 3),\n",
       " (3, 5): (4, 3),\n",
       " (4, 5): (4, 4)}"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPCVPath:\n",
    "    def __init__(self, n_groups, n_test_groups):\n",
    "        self.n_groups = n_groups\n",
    "        self.n_test_groups = n_test_groups\n",
    "        # calculate test_groups combinations\n",
    "        self.combination = list(combinations([x for x in range(n_groups)], n_test_groups))\n",
    "        self._set_path_indexes()\n",
    "    def _set_path_indexes(self):\n",
    "        cnt_path = [0 for _ in range(self.n_groups)]\n",
    "        print (\"cnt_path: \", cnt_path)\n",
    "        self.pairs = {}\n",
    "        for group in self.combination:\n",
    "            print (\"-----------------------\")\n",
    "            print (\"Group: \", group)\n",
    "            temp_path = [0 for _ in range(len(group))]\n",
    "            print (\"temp_path: \", temp_path)\n",
    "            for idx, group_index in enumerate(group):\n",
    "                temp_path[idx] = cnt_path[group_index]\n",
    "                print (\"group_index : \", group_index)\n",
    "                print (\"cnt_path[group_index]: \", cnt_path[group_index])\n",
    "                cnt_path[group_index] += 1\n",
    "            self.pairs[group] = tuple(temp_path)\n",
    "    def get_path(self, test_group_indexes):\n",
    "        return self.pairs[test_group_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt_path:  [0, 0, 0, 0, 0, 0]\n",
      "-----------------------\n",
      "Group:  (0, 1, 2)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  0\n",
      "cnt_path[group_index]:  0\n",
      "group_index :  1\n",
      "cnt_path[group_index]:  0\n",
      "group_index :  2\n",
      "cnt_path[group_index]:  0\n",
      "-----------------------\n",
      "Group:  (0, 1, 3)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  0\n",
      "cnt_path[group_index]:  1\n",
      "group_index :  1\n",
      "cnt_path[group_index]:  1\n",
      "group_index :  3\n",
      "cnt_path[group_index]:  0\n",
      "-----------------------\n",
      "Group:  (0, 1, 4)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  0\n",
      "cnt_path[group_index]:  2\n",
      "group_index :  1\n",
      "cnt_path[group_index]:  2\n",
      "group_index :  4\n",
      "cnt_path[group_index]:  0\n",
      "-----------------------\n",
      "Group:  (0, 1, 5)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  0\n",
      "cnt_path[group_index]:  3\n",
      "group_index :  1\n",
      "cnt_path[group_index]:  3\n",
      "group_index :  5\n",
      "cnt_path[group_index]:  0\n",
      "-----------------------\n",
      "Group:  (0, 2, 3)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  0\n",
      "cnt_path[group_index]:  4\n",
      "group_index :  2\n",
      "cnt_path[group_index]:  1\n",
      "group_index :  3\n",
      "cnt_path[group_index]:  1\n",
      "-----------------------\n",
      "Group:  (0, 2, 4)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  0\n",
      "cnt_path[group_index]:  5\n",
      "group_index :  2\n",
      "cnt_path[group_index]:  2\n",
      "group_index :  4\n",
      "cnt_path[group_index]:  1\n",
      "-----------------------\n",
      "Group:  (0, 2, 5)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  0\n",
      "cnt_path[group_index]:  6\n",
      "group_index :  2\n",
      "cnt_path[group_index]:  3\n",
      "group_index :  5\n",
      "cnt_path[group_index]:  1\n",
      "-----------------------\n",
      "Group:  (0, 3, 4)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  0\n",
      "cnt_path[group_index]:  7\n",
      "group_index :  3\n",
      "cnt_path[group_index]:  2\n",
      "group_index :  4\n",
      "cnt_path[group_index]:  2\n",
      "-----------------------\n",
      "Group:  (0, 3, 5)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  0\n",
      "cnt_path[group_index]:  8\n",
      "group_index :  3\n",
      "cnt_path[group_index]:  3\n",
      "group_index :  5\n",
      "cnt_path[group_index]:  2\n",
      "-----------------------\n",
      "Group:  (0, 4, 5)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  0\n",
      "cnt_path[group_index]:  9\n",
      "group_index :  4\n",
      "cnt_path[group_index]:  3\n",
      "group_index :  5\n",
      "cnt_path[group_index]:  3\n",
      "-----------------------\n",
      "Group:  (1, 2, 3)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  1\n",
      "cnt_path[group_index]:  4\n",
      "group_index :  2\n",
      "cnt_path[group_index]:  4\n",
      "group_index :  3\n",
      "cnt_path[group_index]:  4\n",
      "-----------------------\n",
      "Group:  (1, 2, 4)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  1\n",
      "cnt_path[group_index]:  5\n",
      "group_index :  2\n",
      "cnt_path[group_index]:  5\n",
      "group_index :  4\n",
      "cnt_path[group_index]:  4\n",
      "-----------------------\n",
      "Group:  (1, 2, 5)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  1\n",
      "cnt_path[group_index]:  6\n",
      "group_index :  2\n",
      "cnt_path[group_index]:  6\n",
      "group_index :  5\n",
      "cnt_path[group_index]:  4\n",
      "-----------------------\n",
      "Group:  (1, 3, 4)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  1\n",
      "cnt_path[group_index]:  7\n",
      "group_index :  3\n",
      "cnt_path[group_index]:  5\n",
      "group_index :  4\n",
      "cnt_path[group_index]:  5\n",
      "-----------------------\n",
      "Group:  (1, 3, 5)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  1\n",
      "cnt_path[group_index]:  8\n",
      "group_index :  3\n",
      "cnt_path[group_index]:  6\n",
      "group_index :  5\n",
      "cnt_path[group_index]:  5\n",
      "-----------------------\n",
      "Group:  (1, 4, 5)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  1\n",
      "cnt_path[group_index]:  9\n",
      "group_index :  4\n",
      "cnt_path[group_index]:  6\n",
      "group_index :  5\n",
      "cnt_path[group_index]:  6\n",
      "-----------------------\n",
      "Group:  (2, 3, 4)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  2\n",
      "cnt_path[group_index]:  7\n",
      "group_index :  3\n",
      "cnt_path[group_index]:  7\n",
      "group_index :  4\n",
      "cnt_path[group_index]:  7\n",
      "-----------------------\n",
      "Group:  (2, 3, 5)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  2\n",
      "cnt_path[group_index]:  8\n",
      "group_index :  3\n",
      "cnt_path[group_index]:  8\n",
      "group_index :  5\n",
      "cnt_path[group_index]:  7\n",
      "-----------------------\n",
      "Group:  (2, 4, 5)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  2\n",
      "cnt_path[group_index]:  9\n",
      "group_index :  4\n",
      "cnt_path[group_index]:  8\n",
      "group_index :  5\n",
      "cnt_path[group_index]:  8\n",
      "-----------------------\n",
      "Group:  (3, 4, 5)\n",
      "temp_path:  [0, 0, 0]\n",
      "group_index :  3\n",
      "cnt_path[group_index]:  9\n",
      "group_index :  4\n",
      "cnt_path[group_index]:  9\n",
      "group_index :  5\n",
      "cnt_path[group_index]:  9\n"
     ]
    }
   ],
   "source": [
    "cppath = CPCVPath(6, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1, 2): (0, 0, 0),\n",
       " (0, 1, 3): (1, 1, 0),\n",
       " (0, 1, 4): (2, 2, 0),\n",
       " (0, 1, 5): (3, 3, 0),\n",
       " (0, 2, 3): (4, 1, 1),\n",
       " (0, 2, 4): (5, 2, 1),\n",
       " (0, 2, 5): (6, 3, 1),\n",
       " (0, 3, 4): (7, 2, 2),\n",
       " (0, 3, 5): (8, 3, 2),\n",
       " (0, 4, 5): (9, 3, 3),\n",
       " (1, 2, 3): (4, 4, 4),\n",
       " (1, 2, 4): (5, 5, 4),\n",
       " (1, 2, 5): (6, 6, 4),\n",
       " (1, 3, 4): (7, 5, 5),\n",
       " (1, 3, 5): (8, 6, 5),\n",
       " (1, 4, 5): (9, 6, 6),\n",
       " (2, 3, 4): (7, 7, 7),\n",
       " (2, 3, 5): (8, 8, 7),\n",
       " (2, 4, 5): (9, 8, 8),\n",
       " (3, 4, 5): (9, 9, 9)}"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cppath.pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "\n",
    "\n",
    "def ml_get_train_times(samples_info_sets: pd.Series, test_times: pd.Series) -> pd.Series:\n",
    "    # pylint: disable=invalid-name\n",
    "    \"\"\"\n",
    "    Advances in Financial Machine Learning, Snippet 7.1, page 106.\n",
    "\n",
    "    Purging observations in the training set\n",
    "\n",
    "    This function find the training set indexes given the information on which each record is based\n",
    "    and the range for the test set.\n",
    "    Given test_times, find the times of the training observations.\n",
    "\n",
    "    :param samples_info_sets: (pd.Series) The information range on which each record is constructed from\n",
    "        *samples_info_sets.index*: Time when the information extraction started.\n",
    "        *samples_info_sets.value*: Time when the information extraction ended.\n",
    "    :param test_times: (pd.Series) Times for the test dataset.\n",
    "    :return: (pd.Series) Training set\n",
    "    \"\"\"\n",
    "    train = samples_info_sets.copy(deep=True)\n",
    "    # train.index : train start index \n",
    "    # train : train end index\n",
    "    \n",
    "    for start_ix, end_ix in test_times.iteritems():\n",
    "        df0 = train[(start_ix <= train.index) & (train.index <= end_ix)].index  # Train starts within test\n",
    "        df1 = train[(start_ix <= train) & (train <= end_ix)].index  # Train ends within test\n",
    "        df2 = train[(train.index <= start_ix) & (end_ix <= train)].index  # Train envelops test\n",
    "        train = train.drop(df0.union(df1).union(df2))\n",
    "        \n",
    "    return train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from itertools import combinations\n",
    "\n",
    "# combination \n",
    "total_split_num = 10\n",
    "val_split_num = 2\n",
    "\n",
    "folds = [i for i in range(total_split_num)]\n",
    "val_comb = list(combinations(folds, val_split_num))\n",
    "fold_set = [(ix[0], ix[-1] + 1) for ix in np.array_split(np.arange(X.shape[0]), 6)]\n",
    "\n",
    "\n",
    "# Path Generation \n",
    "train_split_num = total_split_num - val_split_num\n",
    "\n",
    "path_fold_num  = train_split_num + 1 # 한 path 에 존재하는 fold 의 개수 / train_split_num + 1  = 5\n",
    "path_num = int(len(val_comb) * val_split_num / total_split_num) # 전체 path 의 개수 = path_fold_num \n",
    "\n",
    "model_num = len(val_comb) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPCV\n",
    "- Combination \n",
    "- purging\n",
    "- embargo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implements the Combinatorial Purged Cross-Validation class from Chapter 12\n",
    "\"\"\"\n",
    "import sys \n",
    "\n",
    "\n",
    "from itertools import combinations\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.special import comb\n",
    "from sklearn.model_selection import KFold\n",
    "# from .cross_validation import ml_get_train_times\n",
    "\n",
    "\n",
    "def _get_number_of_backtest_paths(n_train_splits: int, n_test_splits: int) -> float:\n",
    "    \"\"\"\n",
    "    Number of combinatorial paths for CPCV(N,K)\n",
    "    :param n_train_splits: (int) number of train splits\n",
    "    :param n_test_splits: (int) number of test splits\n",
    "    :return: (int) number of backtest paths for CPCV(N,k)\n",
    "    \"\"\"\n",
    "    return int(comb(n_train_splits, n_train_splits - n_test_splits) * n_test_splits / n_train_splits)\n",
    "\n",
    "\n",
    "class CombinatorialPurgedKFold(KFold):\n",
    "    \"\"\"\n",
    "    Advances in Financial Machine Learning, Chapter 12.\n",
    "\n",
    "    Implements Combinatial Purged Cross Validation (CPCV)\n",
    "\n",
    "    The train is purged of observations overlapping test-label intervals\n",
    "    Test set is assumed contiguous (shuffle=False), w/o training samples in between\n",
    "\n",
    "    :param n_splits: (int) The number of splits. Default to 3\n",
    "    :param samples_info_sets: (pd.Series) The information range on which each record is constructed from\n",
    "        *samples_info_sets.index*: Time when the information extraction started.\n",
    "        *samples_info_sets.value*: Time when the information extraction ended.\n",
    "    :param pct_embargo: (float) Percent that determines the embargo size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_splits: int = 3,\n",
    "                 n_test_splits: int = 2,\n",
    "                 samples_info_sets: pd.Series = None,\n",
    "                 pct_embargo: float = 0.):\n",
    "\n",
    "        if not isinstance(samples_info_sets, pd.Series):\n",
    "            raise ValueError('The samples_info_sets param must be a pd.Series')\n",
    "        super(CombinatorialPurgedKFold, self).__init__(n_splits, shuffle=False, random_state=None)\n",
    "\n",
    "        self.samples_info_sets = samples_info_sets\n",
    "        self.pct_embargo = pct_embargo\n",
    "        self.n_test_splits = n_test_splits\n",
    "        self.num_backtest_paths = _get_number_of_backtest_paths(self.n_splits, self.n_test_splits)\n",
    "        self.backtest_paths = []  # Array of backtest paths\n",
    "\n",
    "    def _generate_combinatorial_test_ranges(self, splits_indices: dict) -> List:\n",
    "        \"\"\"\n",
    "        Using start and end indices of test splits from KFolds and number of test_splits (self.n_test_splits),\n",
    "        generates combinatorial test ranges splits\n",
    "\n",
    "        :param splits_indices: (dict) Test fold integer index: [start test index, end test index]\n",
    "        :return: (list) Combinatorial test splits ([start index, end index])\n",
    "        \"\"\"\n",
    "\n",
    "        # Possible test splits for each fold\n",
    "        combinatorial_splits = list(combinations(list(splits_indices.keys()), self.n_test_splits))\n",
    "        combinatorial_test_ranges = []  # List of test indices formed from combinatorial splits\n",
    "        for combination in combinatorial_splits:\n",
    "            temp_test_indices = []  # Array of test indices for current split combination\n",
    "            for int_index in combination:\n",
    "                temp_test_indices.append(splits_indices[int_index])\n",
    "            combinatorial_test_ranges.append(temp_test_indices)\n",
    "        return combinatorial_test_ranges\n",
    "\n",
    "    def _fill_backtest_paths(self, train_indices: list, test_splits: list):\n",
    "        \"\"\"\n",
    "        Using start and end indices of test splits and purged/embargoed train indices from CPCV, find backtest path and\n",
    "        place in the path where these indices should be used.\n",
    "\n",
    "        :param test_splits: (list) of lists with first element corresponding to test start index and second - test end\n",
    "        \"\"\"\n",
    "        # Fill backtest paths using train/test splits from CPCV\n",
    "        for split in test_splits:\n",
    "            found = False  # Flag indicating that split was found and filled in one of backtest paths\n",
    "            for path in self.backtest_paths:\n",
    "                for path_el in path:\n",
    "                    if path_el['train'] is None and split == path_el['test'] and found is False:\n",
    "                        path_el['train'] = np.array(train_indices)\n",
    "                        path_el['test'] = list(range(split[0], split[-1]))\n",
    "                        found = True\n",
    "\n",
    "    # noinspection PyPep8Naming\n",
    "    def split(self,\n",
    "              X: pd.DataFrame,\n",
    "              y: pd.Series = None,\n",
    "              groups=None):\n",
    "        \"\"\"\n",
    "        The main method to call for the PurgedKFold class\n",
    "\n",
    "        :param X: (pd.DataFrame) Samples dataset that is to be split\n",
    "        :param y: (pd.Series) Sample labels series\n",
    "        :param groups: (array-like), with shape (n_samples,), optional\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        :return: (tuple) [train list of sample indices, and test list of sample indices]\n",
    "        \"\"\"\n",
    "        if X.shape[0] != self.samples_info_sets.shape[0]:\n",
    "            raise ValueError(\"X and the 'samples_info_sets' series param must be the same length\")\n",
    "\n",
    "        test_ranges: [(int, int)] = [(ix[0], ix[-1] + 1) for ix in np.array_split(np.arange(X.shape[0]), self.n_splits)]\n",
    "        splits_indices = {}\n",
    "        for index, [start_ix, end_ix] in enumerate(test_ranges):\n",
    "            splits_indices[index] = [start_ix, end_ix]\n",
    "\n",
    "        combinatorial_test_ranges = self._generate_combinatorial_test_ranges(splits_indices)\n",
    "        # Prepare backtest paths\n",
    "        for _ in range(self.num_backtest_paths):\n",
    "            path = []\n",
    "            for split_idx in splits_indices.values():\n",
    "                path.append({'train': None, 'test': split_idx})\n",
    "            self.backtest_paths.append(path)\n",
    "\n",
    "        embargo: int = int(X.shape[0] * self.pct_embargo)\n",
    "        \n",
    "        for test_splits in combinatorial_test_ranges:\n",
    "            \n",
    "            # Embargo\n",
    "            test_times = pd.Series(index=[self.samples_info_sets[ix[0]] for ix in test_splits], data=[\n",
    "                self.samples_info_sets[ix[1] - 1] if ix[1] - 1 + embargo >= X.shape[0] else self.samples_info_sets[\n",
    "                    ix[1] - 1 + embargo]\n",
    "                for ix in test_splits])\n",
    "\n",
    "            test_indices = []\n",
    "            for [start_ix, end_ix] in test_splits:\n",
    "                test_indices.append(list(range(start_ix, end_ix)))\n",
    "\n",
    "            # Purge\n",
    "            train_times = ml_get_train_times(self.samples_info_sets, test_times)\n",
    "\n",
    "            # Get indices\n",
    "            train_indices = []\n",
    "            for train_ix in train_times.index:\n",
    "                train_indices.append(self.samples_info_sets.index.get_loc(train_ix))\n",
    "\n",
    "            self._fill_backtest_paths(train_indices, test_splits)\n",
    "\n",
    "            yield np.array(train_indices), [np.array(x) for x in test_indices] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combinatorial_test_ranges' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11052/2984314140.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcombinatorial_test_ranges\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'combinatorial_test_ranges' is not defined"
     ]
    }
   ],
   "source": [
    "combinatorial_test_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_prices = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_name = None\n",
    "number_of_assets = None\n",
    "time = None\n",
    "length_of_time = None\n",
    "first_weights = None\n",
    "all_weights = None\n",
    "\n",
    "asset_name, number_of_assets, time, length_of_time, first_weights, all_weights = initialize(asset_prices)\n",
    "monthly_return = calculate_return(asset_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = monthly_return[1:-12].copy() # 마지막 12 제외\n",
    "test_data = monthly_return[-24:].copy() # 마지막 24 부터 시작\n",
    "# test_data.drop(['B','N','P'],axis=1 ,inplace=True)\n",
    "training_data_array = np.array(training_data)\n",
    "test_data_array = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_points = 12\n",
    "\n",
    "sample_info_sets = pd.Series(index=training_data[:-history_points].index, data=training_data[history_points:].index)\n",
    "    # history_points 간격을 유지하면서 진행 \n",
    "\n",
    "pct_embargo = 0.01\n",
    "\n",
    "cv_gen_purged = CombinatorialPurgedKFold(n_splits=total_split_num, n_test_splits= val_split_num, samples_info_sets=sample_info_sets, pct_embargo=pct_embargo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "1997-05-20    1997-06-05\n",
       "1997-05-21    1997-06-06\n",
       "1997-05-22    1997-06-09\n",
       "1997-05-23    1997-06-10\n",
       "1997-05-26    1997-06-11\n",
       "                 ...    \n",
       "2021-09-28    2021-10-14\n",
       "2021-09-29    2021-10-15\n",
       "2021-09-30    2021-10-18\n",
       "2021-10-01    2021-10-19\n",
       "2021-10-04    2021-10-20\n",
       "Name: date, Length: 6360, dtype: object"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_info_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>13ty_index</th>\n",
       "      <th>interty_index</th>\n",
       "      <th>lty_index</th>\n",
       "      <th>mbs_index</th>\n",
       "      <th>13cy_index</th>\n",
       "      <th>intercy_index</th>\n",
       "      <th>lcy_index</th>\n",
       "      <th>ty_index</th>\n",
       "      <th>cy_index</th>\n",
       "      <th>agg_index</th>\n",
       "      <th>real_known</th>\n",
       "      <th>cat_obs1</th>\n",
       "      <th>cat_obs2</th>\n",
       "      <th>cat_knwon1</th>\n",
       "      <th>cat_knwon2</th>\n",
       "      <th>static</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-05-20</th>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>3.545289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-21</th>\n",
       "      <td>0.000075</td>\n",
       "      <td>-0.000484</td>\n",
       "      <td>-0.004605</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.001096</td>\n",
       "      <td>-0.003869</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>-0.002089</td>\n",
       "      <td>-0.001089</td>\n",
       "      <td>-0.747206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-22</th>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-0.000382</td>\n",
       "      <td>-0.002164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>-0.000826</td>\n",
       "      <td>-0.001186</td>\n",
       "      <td>-0.000601</td>\n",
       "      <td>0.235188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>2.086691</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.749731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            13ty_index  interty_index  lty_index  mbs_index  13cy_index  \\\n",
       "date                                                                      \n",
       "1997-05-20    0.000899       0.001007  -0.000357   0.000599    0.000958   \n",
       "1997-05-21    0.000075      -0.000484  -0.004605   0.000200    0.000045   \n",
       "1997-05-22   -0.000075      -0.000382  -0.002164   0.000000   -0.000090   \n",
       "1997-05-23    0.000000       0.000472   0.001114   0.000399    0.000000   \n",
       "1997-05-26    0.000000       0.000000   0.000000   0.000000    0.000000   \n",
       "\n",
       "            intercy_index  lcy_index  ty_index  cy_index  agg_index  \\\n",
       "date                                                                  \n",
       "1997-05-20       0.001097  -0.000197  0.000667  0.000592   0.000601   \n",
       "1997-05-21      -0.001096  -0.003869 -0.001503 -0.002089  -0.001089   \n",
       "1997-05-22      -0.000694  -0.002091 -0.000826 -0.001186  -0.000601   \n",
       "1997-05-23       0.000694   0.001003  0.000620  0.000792   0.000601   \n",
       "1997-05-26       0.000000   0.000000  0.000000  0.000000   0.000000   \n",
       "\n",
       "            real_known  cat_obs1  cat_obs2  cat_knwon1  cat_knwon2  static  \n",
       "date                                                                        \n",
       "1997-05-20    3.545289       0.0      -0.5        0.25    0.333333     0.0  \n",
       "1997-05-21   -0.747206       0.0       0.0       -0.20    0.000000     0.0  \n",
       "1997-05-22    0.235188       0.0       0.0       -0.25    0.000000     0.0  \n",
       "1997-05-23    2.086691      -1.0       1.0        0.00   -0.250000     0.0  \n",
       "1997-05-26   -0.749731       0.0      -0.5        0.00    0.000000     0.0  "
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "1997-05-20    1997-06-05\n",
       "1997-05-21    1997-06-06\n",
       "1997-05-22    1997-06-09\n",
       "1997-05-23    1997-06-10\n",
       "1997-05-26    1997-06-11\n",
       "                 ...    \n",
       "2021-09-28    2021-10-14\n",
       "2021-09-29    2021-10-15\n",
       "2021-09-30    2021-10-18\n",
       "2021-10-01    2021-10-19\n",
       "2021-10-04    2021-10-20\n",
       "Name: date, Length: 6360, dtype: object"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_info_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 \n",
    "\n",
    "all_X_training_data = np.array([training_data_array[i:i+history_points].copy() for i in range(len(training_data_array) - history_points)])\n",
    "all_y_training_data = np.array([training_data_array[i + history_points].copy() for i in range(len(training_data_array) - history_points)])\n",
    "gen = cv_gen_purged.split(X=all_X_training_data, y=all_y_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6360, 12, 16)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_X_training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6360, 12, 16)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_X_training_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPCV with Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch \n",
    "from torch import nn \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_num = 32\n",
    "epoch_num = 10\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(Model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6360, 12, 16)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_X_training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6360, 16)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_y_training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1997-05-19', '1997-05-20', '1997-05-21', ..., '2016-11-14',\n",
       "       '2016-11-15', '2016-11-16'], dtype=object)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df.index)[train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 2\n",
    "\n",
    "total_loss = [0 for i in range(path_num)]\n",
    "\n",
    "for train_ind, (train, valid_set) in enumerate(gen): # 결국 순서대로 -> 순서 자체가 train model number\n",
    "    i +=1\n",
    "\n",
    "    # print ('i:', i)\n",
    "    # MODEL INIT\n",
    "\n",
    "    # TRAIN     \n",
    "    # TRAIN Dataloader generation \n",
    "\n",
    "    train_ds = TensorDataset(all_X_training_data[train], all_y_training_data[train])\n",
    "    train_dl = DataLoader(train_ds, batch_size = batch_num, shuffle = True)\n",
    "    \n",
    "    # Epoch \n",
    "    for epoch in range(epoch_num):\n",
    "        Model.train()\n",
    "        epoch_train_loss = []\n",
    "        \n",
    "        for train_x, train_y in train_dl:\n",
    "\n",
    "            train_pred = Model(train_x)\n",
    "            \n",
    "            loss_train = criterion(train_pred, train_y)\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "\n",
    "    # pred_tr = Model(TRAIN)\n",
    "    # loss_tr = criterion(pred_tr, label)\n",
    "    \n",
    "    # TEST \n",
    "        # TEST Dataloader generation \n",
    "    Model.eval()\n",
    "    for val_ind, valid in enumerate(valid_set):\n",
    "        # print ('len vald: ', len(valid_set))\n",
    "        valid_ds = TensorDataset(all_X_training_data[valid], all_y_training_data[valid])\n",
    "        valid_dl = DataLoader(valid_ds, batch_size = batch_num, shuffle = True)\n",
    "        \n",
    "        for valid_x, valid_y in valid_dl:\n",
    "            \n",
    "            val_pred = Model(valid_x)\n",
    "            \n",
    "            criterion(val_pred, valid_y)\n",
    "            \n",
    "            \n",
    "        path_ind = train_valid_path[(train_ind, val_ind)]\n",
    "        # print (train_ind, val_ind)\n",
    "        # print (\"path_ind: \", path_ind)    \n",
    "        # total_loss[path_ind] += loss_val\n",
    "        \n",
    "for i in range(len(total_loss)):\n",
    "    total_loss[i] /= n_test\n",
    "\n",
    "\n",
    "\n",
    "# print (\"\\n\")\n",
    "# print (\"train shape: \", train.shape, \"valid shape: \", valid.shape)\n",
    "# train_shape_ls.append(train.shape)\n",
    "# valid_shape_ls.append(valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 5085, 5086, 5087])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5088, 66, 16, 1)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[train].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5088,)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ind, val_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_valid_path[train_ind, val_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train - Test -Path 로 이어지는 dictionary 만들기 \n",
    "\n",
    "path_ind = 0\n",
    "\n",
    "train_test_path = {\n",
    "    [i] for i in range(model_num)\n",
    "}\n",
    "\n",
    "train_ls = total_path_train[path_ind]\n",
    "for train_ind in train_ls: \n",
    "    train_test_path[]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X, Y generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_xy_seq(df: pd.DataFrame, x_seq = 66, y_seq = 22):\n",
    "    \"\"\"\n",
    "    Generate samples from\n",
    "    :param df:\n",
    "    :param x_seq:\n",
    "    :param y_seq:\n",
    "    :param scaler:\n",
    "    :return:\n",
    "    # x: (epoch_size, input_length, num_nodes, input_dim)\n",
    "    # y: (epoch_size, output_length, num_nodes, output_dim)\n",
    "    \"\"\"\n",
    "    num_samples, num_nodes = df.shape\n",
    "    dates_arr = np.array(df.index)\n",
    "    data = np.expand_dims(df.values, axis = -1) # df -> array [N, F, 1]\n",
    "\n",
    "    x_offsets = np.arange(-x_seq+1, 1)  \n",
    "    y_offsets = np.arange(1, y_seq+1)\n",
    "\n",
    "    # feature_list = [data]\n",
    "\n",
    "    x, y = [], []\n",
    "    x_date, y_date = [],[]\n",
    "\n",
    "    min_t = abs(min(x_offsets))\n",
    "    max_t = abs(num_samples - abs(max(y_offsets)))\n",
    "\n",
    "    for t in range(min_t, max_t):\n",
    "        # value seperation\n",
    "        x.append(data[t+x_offsets, ...])\n",
    "        y.append(data[t+y_offsets, ...])\n",
    "        # date seperation\n",
    "        x_date.append(dates_arr[t+x_offsets])\n",
    "        y_date.append(dates_arr[t+y_offsets])\n",
    "        \n",
    "    x = np.stack(x, axis = 0)\n",
    "    y = np.stack(y, axis = 0)\n",
    "\n",
    "    x_date = np.stack(x_date, axis = 0)\n",
    "    y_date = np.stack(y_date, axis = 0)\n",
    "\n",
    "    return x, y, x_date, y_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, x_date, y_date = generate_xy_seq(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6298, 66, 16, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6298, 66)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_date.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPCV\n",
    "- 6C2\n",
    "- purging\n",
    "- embargo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(asset_prices):\n",
    "    '''\n",
    "    필요한 값들 생성\n",
    "\n",
    "    :param asset_prices: (pd.DataFrame) Asset prices\n",
    "    '''\n",
    "    asset_name       = asset_prices.columns\n",
    "    number_of_assets = asset_name.size\n",
    "    time             = asset_prices.index\n",
    "    length_of_time   = time.size\n",
    "    first_weights    = np.ones(number_of_assets) / number_of_assets \n",
    "    all_weights      = np.zeros((length_of_time + 1, number_of_assets))\n",
    "\n",
    "    return asset_name, number_of_assets, time, length_of_time, first_weights, all_weights\n",
    "\n",
    "\n",
    "def calculate_return(asset_prices, resample_by=None):\n",
    "    \"\"\"\n",
    "    수익률 계산 , 기간 resample 가능하게 만들기\n",
    "\n",
    "    :param asset_prices: (pd.DataFrame) Asset prices\n",
    "    :param resample_by: (str) Period to resample data, None for no resampling\n",
    "    :return: (pd.DataFrame) Returns per asset\n",
    "    \"\"\"\n",
    "    if resample_by:\n",
    "        asset_prices = asset_prices.resample(resample_by).last()\n",
    "    asset_returns = asset_prices.pct_change().fillna(0)\n",
    "    return asset_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터분리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "# for i in range(10):\n",
    "a.append(list(range(1,10)))\n",
    "a.append(list(range(45,85)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61,\n",
       "        62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78,\n",
       "        79, 80, 81, 82, 83, 84])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.array(x) for x in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 2\n",
      "current test_splits:  [[0, 1060], [2120, 3180]]\n",
      "[0] [2]\n",
      "\n",
      "\n",
      "train shape:  (4090,) valid shape:  (2120,)\n"
     ]
    }
   ],
   "source": [
    "i +=1\n",
    "print ('i:', i)\n",
    "train, valid = next(gen)\n",
    "print (\"\\n\")\n",
    "print (\"train shape: \", train.shape, \"valid shape: \", valid.shape)\n",
    "train_shape_ls.append(train.shape)\n",
    "valid_shape_ls.append(valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2120\n"
     ]
    }
   ],
   "source": [
    "print ((1060-0)+(6360 - 5300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4165,), (4090,)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_shape_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2120,), (2120,)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_shape_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_dict = {}\n",
    "\n",
    "for key, value in enumerate(fold_set):\n",
    "    fold_dict[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0, 852),\n",
       " 1: (852, 1704),\n",
       " 2: (1704, 2555),\n",
       " 3: (2555, 3406),\n",
       " 4: (3406, 4257),\n",
       " 5: (4257, 5108)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_splits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32372\\1601335919.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_splits' is not defined"
     ]
    }
   ],
   "source": [
    "test_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinatorial_test_ranges = cv_gen_purged._generate_combinatorial_test_ranges(fold_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 852), (852, 1704)],\n",
       " [(0, 852), (1704, 2555)],\n",
       " [(0, 852), (2555, 3406)],\n",
       " [(0, 852), (3406, 4257)],\n",
       " [(0, 852), (4257, 5108)],\n",
       " [(852, 1704), (1704, 2555)],\n",
       " [(852, 1704), (2555, 3406)],\n",
       " [(852, 1704), (3406, 4257)],\n",
       " [(852, 1704), (4257, 5108)],\n",
       " [(1704, 2555), (2555, 3406)],\n",
       " [(1704, 2555), (3406, 4257)],\n",
       " [(1704, 2555), (4257, 5108)],\n",
       " [(2555, 3406), (3406, 4257)],\n",
       " [(2555, 3406), (4257, 5108)],\n",
       " [(3406, 4257), (4257, 5108)]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinatorial_test_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combinatorial_test_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1997-06-05'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_info_sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "1997-05-20    1997-06-05\n",
       "1997-05-21    1997-06-06\n",
       "1997-05-22    1997-06-09\n",
       "1997-05-23    1997-06-10\n",
       "1997-05-26    1997-06-11\n",
       "                 ...    \n",
       "2021-09-28    2021-10-14\n",
       "2021-09-29    2021-10-15\n",
       "2021-09-30    2021-10-18\n",
       "2021-10-01    2021-10-19\n",
       "2021-10-04    2021-10-20\n",
       "Name: date, Length: 6360, dtype: object"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_info_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26b462196a458278e1b93f4dafd0c6a4f17b941fc39fbc23177d70dd3e3b7653"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('tft')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
